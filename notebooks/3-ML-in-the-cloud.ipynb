{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6968aa14-ef6d-4537-bc7e-61a5d9d314dd",
   "metadata": {},
   "source": [
    "## Lesson 3: Writing Flows for the Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d99b145-584d-4c8b-b2b8-a3ddf3ee2d72",
   "metadata": {},
   "source": [
    "## Learning objectives of this lesson\n",
    "\n",
    "* How to burst to the cloud with you ML workflows!\n",
    "* How to use `--with batch` to access cloud compute.\n",
    "* How to define step-level dependencies using the `@conda` decorator.\n",
    "\n",
    "In this lesson, we'll show how to get Metaflow working on the cloud for when you need to access more compute, for example. We'll be using AWS for the purposes of this lesson. I've configured my AWS so that I can access it from this Jupyter notebook. \n",
    "\n",
    "\n",
    "To reproduce this, you'll require access to compute and storage resources on AWS, which you'll need to configure. A few ways to do this are:\n",
    "- If you have an existing account, there’s a ready-made recipe, so called CloudFormation Template, that you can execute on your account. Go to [docs.metaflow.org](docs.metaflow.org) to learn more.\n",
    "- If you don’t have an account (or you can’t use your company account, say), you can request a Metaflow Sandbox [here](https://docs.metaflow.org/metaflow-on-aws/metaflow-sandbox), which gives you a full AWS test environment for free to test with\n",
    "- If you have any trouble with this, the [Metaflow community Slack](https://outerbounds-community.slack.com) is super friendly helpful for newcomers. You can join and ask for help!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73770c7-0d00-447b-9ffa-1f878a5b2c9e",
   "metadata": {},
   "source": [
    "## Why the Cloud?\n",
    "\n",
    "If you're asking \"Why should I care about running ML on AWS?\", that's a great question. One answer is scalability: It’s like a huge massive laptop. And not only that, but infinitely many huge massive laptops at your fingertips!\n",
    "\n",
    "Have you ever had a Pandas dataframe that runs out of memory because maybe you have 16GB on your laptop. Sure, you could restructure your code to do it differently, or use a smaller dataset, but there’s a better way. What if I told you that you could press a button and get more memory installed on your laptop in seconds - that’s essentially what the cloud gives you!\n",
    "\n",
    "On top of this, a cloud-based workstation can pay big dividends when it comes to security, operational concerns, scalability, and interaction with production deployments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3a61bd-7792-44a9-a2b7-f919a3b1f7ff",
   "metadata": {},
   "source": [
    "## Random Forest flows on the cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c868e0-5a3e-43e8-b5bf-8a34c6170166",
   "metadata": {},
   "source": [
    "In this section, we'll get our random forest flows up and running on AWS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd051a23-afc8-456f-bac1-37451f35d052",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../flows/cloud/rf_flow_cloud.py\n",
    "\n",
    "from metaflow import FlowSpec, step, card, conda\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class RF_Flow_cloud(FlowSpec):\n",
    "    \"\"\"\n",
    "    train a random forest\n",
    "    \"\"\"\n",
    "    @conda(libraries={'scikit-learn':'1.0.2'}) \n",
    "    @card\n",
    "    @step\n",
    "    def start(self):\n",
    "        \"\"\"\n",
    "        Load the data\n",
    "        \"\"\"\n",
    "        #Import scikit-learn dataset library\n",
    "        from sklearn import datasets\n",
    "\n",
    "        #Load dataset\n",
    "        self.iris = datasets.load_iris()\n",
    "        self.X = self.iris['data']\n",
    "        self.y = self.iris['target']\n",
    "        self.next(self.rf_model)\n",
    "        \n",
    "    @conda(libraries={'scikit-learn':'1.0.2'})\n",
    "    @step\n",
    "    def rf_model(self):\n",
    "        \"\"\"\n",
    "        build random forest model\n",
    "        \"\"\"\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        \n",
    "        self.clf = RandomForestClassifier(n_estimators=10, max_depth=None,\n",
    "            min_samples_split=2, random_state=0)\n",
    "        self.next(self.train)\n",
    "\n",
    "        \n",
    "    @conda(libraries={'scikit-learn':'1.0.2'})       \n",
    "    @step\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Train the model\n",
    "        \"\"\"\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        self.scores = cross_val_score(self.clf, self.X, self.y, cv=5)\n",
    "        self.next(self.end)\n",
    "        \n",
    "        \n",
    "    @step\n",
    "    def end(self):\n",
    "        \"\"\"\n",
    "        End of flow!\n",
    "        \"\"\"\n",
    "        print(\"ClassificationFlow is all done.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    RF_Flow_cloud()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5efc50-b867-4381-93b8-49cb6e457ce5",
   "metadata": {},
   "source": [
    "Execute the above from the command line with\n",
    "\n",
    "```bash\n",
    "python flows/cloud/rf_flow_cloud.py --environment=conda run --with batch\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab72e87-cf37-47d2-9bd7-18aacb7296e2",
   "metadata": {},
   "source": [
    "While this is executing, let's talk about the differences in the code we just wrote, in particular\n",
    "\n",
    "- the `@conda` decorator and\n",
    "- the `--with batch` option\n",
    "\n",
    "Also note that [you can use the `@batch` decorator to](https://docs.metaflow.org/metaflow/scaling#using-aws-batch-selectively-with-batch-decorator) to \"selectively run some steps locally and some on AWS Batch.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ddc640-3f00-4543-8702-0011834a7d77",
   "metadata": {},
   "source": [
    "Let's also check out the Metaflow card with:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e517acf-097d-438e-a239-4f5d38612cd5",
   "metadata": {},
   "source": [
    "```bash\n",
    "python flows/cloud/rf_flow_cloud.py --environment=conda card view start\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0d688c-8c5b-4ee2-857a-6cdc13400ca6",
   "metadata": {},
   "source": [
    "## Parallel training on the cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6482ec-6d41-4241-8a20-8de5c82d4b55",
   "metadata": {},
   "source": [
    "**HANDS-ON:** Write a flow that gets our parallel training/branching example from Lesson 2 working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1756870-9d37-48bf-b58b-0561e2db5264",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../flows/cloud/tree_branch_flow_cloud_student.py\n",
    "\n",
    "from metaflow import FlowSpec, step, card, conda\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Branch_Flow_Cloud(FlowSpec):\n",
    "    \"\"\"\n",
    "    train multiple tree based methods\n",
    "    \"\"\"\n",
    "    ____\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    Branch_Flow_Cloud()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9fd048-0f2c-4775-81ba-dd429a28689f",
   "metadata": {},
   "source": [
    "Execute the above from the command line with\n",
    "\n",
    "```bash\n",
    "python flows/cloud/tree_branch_flow_cloud.py --environment=conda run --with batch\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c30a9a3-3b21-48fb-92f8-da724803e2a6",
   "metadata": {},
   "source": [
    "Let's also check out the Metaflow card:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60878dac-d91a-47d6-9228-eb50cd77d96b",
   "metadata": {},
   "source": [
    "```bash\n",
    "python flows/cloud/tree_branch_flow_cloud.py --environment=conda card view start\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af51134e-191e-400b-97ee-26c6a0919fe7",
   "metadata": {},
   "source": [
    "## Lesson Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3535d1f6-5b00-4a7f-a208-fae9a756c140",
   "metadata": {},
   "source": [
    "In this lesson, you learnt\n",
    "\n",
    "* How to burst to the cloud with you ML workflows!\n",
    "* How to use `--with batch` to access cloud compute.\n",
    "* How to define step-level dependencies using the `@conda` decorator.\n",
    "\n",
    "Ready to take it to the next level with more powerful hardware? Check out this guide on [scaling model training to GPUs while tuning many models in parallel](https://outerbounds.com/docs/scale-model-training-and-tuning)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:full-stack-metaflow] *",
   "language": "python",
   "name": "conda-env-full-stack-metaflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
