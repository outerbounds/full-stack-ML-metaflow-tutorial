{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiplayer Metaflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharing\n",
    "\n",
    "Data scientist's on the same Metaflow deployment have read access to each other's Metaflow results. \n",
    "This is useful in a project because you can make incremental progress on each other results, without reinventing the wheel.\n",
    "You can also compare approaches, results, and split work in a seamless way.\n",
    "\n",
    "Two concepts and sharing features that you should understand to benefit most from Metaflow in a team setting, are namespaces and projects."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Namespaces\n",
    "\n",
    "[Namespaces](https://docs.metaflow.org/scaling/tagging#namespaces) help you to keep results organized. \n",
    "A flow runs in a namespace, and the Metaflow Client API retrieves results for you based on the active namespace.\n",
    "Namespaces are not about security or access control, but for organizing results by the users who produce and analyze them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaflow import namespace, Metaflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namespace('user:sandbox')\n",
    "Metaflow().flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expect: the same result in this global (None) namespace as the user:sandbox namespace, \n",
    "    # because your sandbox user is the only user on this Metaflow deployment.\n",
    "namespace(None)\n",
    "Metaflow().flows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The production namespace\n",
    "There is a special namespace designated production. Production namespaces are important for a variety of reasons. For example, it helps you add authorization keys to the process of deploying to a valuable Flow's production namespace. \n",
    "\n",
    "To get started in production, find your `Branch_Cloud_Flow` Flow from the previous section and run this command with the file path changed to wherever you place the flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watch the file path if you run in the terminal! \n",
    "\n",
    "# This will take a minute or two the first time it has to build the conda environment.\n",
    "# Find the namespace this flow is deployed in. Is it production? üßê\n",
    "\n",
    "! python ../flows/cloud/tree_branch_cloud_flow_deploy.py --environment=conda argo-workflows create"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output, you will see a line like `namespace(\"user:sandbox\")` or `namespace(\"production:branch_cloud_flow-0-bkst\")`. \n",
    "Copy that line, paste it in the first line of the next cell and run it. Then "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REPLACE THIS LINE WITH YOUR... \n",
    "# namespace(\"production:branch_cloud_flow-X-XXXX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to print your Argo URL\n",
    "import json\n",
    "res = json.load(open(\"/home/workspace/.metaflowconfig/config.json\"))\n",
    "print(\"Go to this URL:\", res['SANDBOX_VSCODE_URL'].replace('vs', 'argo'), \"and click on the second top left tab 'Workflow Templates'. Then come back here and trigger the flow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python ../flows/cloud/tree_branch_cloud_flow_deploy.py --environment=conda argo-workflows trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will return an empty list for a minute or two after Argo UI shows the flow running.\n",
    "Metaflow().flows\n",
    "# Do you see a different set of flows than what you saw above with the global or user namespace. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projects\n",
    "The [`@project decorator`](https://docs.metaflow.org/production/coordinating-larger-metaflow-projects) is for production use cases. \n",
    "\n",
    "It makes available three classes of namespaces that will affect the behavior of a production deployment:\n",
    "1. `user` is the default. It will deploy to a user-specific, private namespace. Use it for testing production deployments.\n",
    "2. `test` denotes custom branches that can be shared amongst multiple users. Use it for deploying experimental versions that can run in parallel with production. Deploy custom branches with `--branch foo`.\n",
    "3. `prod` denotes the global production namespace. Use it for deploying the official production version of the project. Deploy to production with `--production`. For multiple production variants, deploy custom branches with `--production --branch foo`.\n",
    "\n",
    "You don't need to remember these, but they are useful to revisit once you have thought more about the requirements of your ML project.\n",
    "For example, later in this week you will consider how to deploy multiple production variants to score a champion/challenger model on production traffic.\n",
    "\n",
    "### Motivation\n",
    "Consider the situation after you deploy `Branch_Cloud_Flow` to Argo that is running in production. \n",
    "The next time you deploy `Branch_Cloud_Flow` by running the same command you just did a few cells ago,\n",
    "```sh\n",
    "python ../flows/cloud/tree_branch_cloud_flow_deploy.py --environment=conda argo-workflows create\n",
    "```\n",
    "it will overwrite the production `Branch_Cloud_Flow` flow. Clearly, we want more optionality to run experiments.\n",
    "\n",
    "What do you do when the workflow starts performing well, and multiple people want to test their own production deployments without interfering with yours; or if, as a single developer, you want to experiment with multiple independent deployments of your workflow? How do you create a new workflow without overwriting the existing one? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going to --production\n",
    "\n",
    "Metaflow's `@project` decorator makes it easy to specifiy the production namespace. You can use this to deploy workflows in different namespaces, and specify a dedicated production branch that is not for anything experimental.\n",
    "\n",
    "Go to your `flows/cloud/tree_branch_cloud_flow_deploy.py` implementation, and add the `@project` decorator to your flow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python ../flows/cloud/tree_branch_cloud_flow_deploy.py --environment=conda --production argo-workflows create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python ../flows/cloud/tree_branch_cloud_flow_deploy.py --environment=conda --production argo-workflows trigger"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "full-stack-metaflow-corise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
